{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from utils import *\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from utils import *\n",
    "from scipy.spatial import distance\n",
    "\n",
    "class S3VR():\n",
    "    \"\"\"\n",
    "    The S3VR class used to do semi-surpervised regression tasks\n",
    "    \"\"\"\n",
    "    def __init__(self, k_local, k_global, r, beta):\n",
    "        \"\"\"Initialization\n",
    "\n",
    "        Args:\n",
    "            k_local (int): k values for PLR_local\n",
    "            k_global (int): k values for PLR_global\n",
    "            r (float): probability threshold for choosing data pointsw\n",
    "            beta (float): variance parameter\n",
    "        \"\"\"\n",
    "        self.svr = None\n",
    "        self.labeled_X = None\n",
    "        self.unlabeled_X = None\n",
    "        self.y = None\n",
    "        self.dist = None\n",
    "\n",
    "        self.k_local = k_local\n",
    "        self.k_global = k_global\n",
    "        self.r = r\n",
    "        self.beta = beta\n",
    "\n",
    "    def rbf(self, x1, x2, l=1):\n",
    "        \"\"\"Calulate the kernel mappings for x1 and x2\n",
    "\n",
    "        Args:\n",
    "            x1 (np.ndarray): the x1 with shape (n_1, d)\n",
    "            x2 (np.ndarray): the x2 with shape (n_2, d)\n",
    "            l (int, optional): the parameter of normal distribution. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: the rbf kernel vectors\n",
    "        \"\"\"\n",
    "        if ((x1-x2)**2).ndim > 1:\n",
    "            return np.exp(-1 / (2 * (l**2)) * ((x1-x2)**2).sum(axis=1))\n",
    "        else:\n",
    "            return np.array([np.exp(-1 / (2 * (l**2)) * ((x1-x2)**2).sum())])\n",
    "\n",
    "    def calc_distance(self):\n",
    "        self.dist = euclidean_distances(self.unlabeled_X, self.labeled_X)\n",
    "        self.dist = np.argsort(self.dist, axis=1)\n",
    "\n",
    "    def find_nn(self, index, k):\n",
    "        \"\"\"Find the k nearest neighbors of the point\n",
    "\n",
    "        Args:\n",
    "            point (np.ndarray): the data point with shape (d,)\n",
    "            k (int): the number of nearest neighbors\n",
    "\n",
    "        Raises:\n",
    "            ValueError: the labeled X is not loaded\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: the matrix of the nearest neighbors with shape (k, d)\n",
    "        \"\"\"\n",
    "        if self.labeled_X is None:\n",
    "            raise ValueError(\"Not load datasets\")\n",
    "        if self.dist is None:\n",
    "            self.calc_distance()\n",
    "        index = self.dist[index, :k]\n",
    "        return self.labeled_X[index], index\n",
    "\n",
    "    def estimate_distribution(self, is_local):\n",
    "        \"\"\"Estimate the distribution\n",
    "\n",
    "        Args:\n",
    "            is_local (bool): whether use k_local or k_global\n",
    "\n",
    "        Raises:\n",
    "            ValueError: the datasets are not loaded\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, np.ndarray, int: the y_bar with shape (n_unlabeled,), the sigma_2_hat with shape (n_unlabeled,), the number of data points\n",
    "        \"\"\"\n",
    "        if (self.labeled_X is None) or (self.unlabeled_X is None) or (self.y is None):\n",
    "            raise ValueError(\"Not load datasets\")\n",
    "\n",
    "        k = self.k_local if is_local else self.k_global\n",
    "\n",
    "        ones = np.ones((k, 1))\n",
    "        num = self.unlabeled_X.shape[0]\n",
    "        y_hat = np.zeros((num, 1))\n",
    "        sigma_2_hat = np.zeros((num, 1))\n",
    "\n",
    "        for i in range(num):\n",
    "            nn, nn_index = self.find_nn(i, k)\n",
    "            k_star = self.rbf(self.unlabeled_X[i], nn).reshape(-1, 1)\n",
    "            K_hat = self.rbf(nn, nn) - ones @ k_star.T - k_star @ ones.T + self.rbf(self.unlabeled_X[i], self.unlabeled_X[i]) * ones @ ones.T\n",
    "\n",
    "            # Equation (15), PLR paper\n",
    "            cov = self.beta * K_hat + np.identity(k)\n",
    "            # Equation (14), PLR paper\n",
    "            mu = cov @ (ones/k)\n",
    "\n",
    "            y_bar_nn = self.y[nn_index].sum(axis=0) / k\n",
    "            diff = self.y[nn_index].reshape(-1, 1) - y_bar_nn * ones\n",
    "\n",
    "            y_hat[i] = y_bar_nn + mu.T @ diff\n",
    "            sigma_2_hat[i] = diff.T @ cov @ diff / k\n",
    "\n",
    "        return y_hat, sigma_2_hat, num\n",
    "\n",
    "    def data_generation(self):\n",
    "        \"\"\"Generate the combined training datasets\n",
    "\n",
    "        Raises:\n",
    "            ValueError: the datasets are not loaded\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, np.ndarray: the combined training X with shape (n_combined, d) and y with shape (n_combined,)\n",
    "        \"\"\"\n",
    "        if (self.labeled_X is None) or (self.unlabeled_X is None) or (self.y is None):\n",
    "            raise ValueError(\"Not load datasets\")\n",
    "\n",
    "        self.t0 = time()\n",
    "        # estimate distribution\n",
    "        y_local, sigma_2_local, n = self.estimate_distribution(True)\n",
    "        self.t1 = time()\n",
    "        y_global, sigma_2_global, _ = self.estimate_distribution(False)\n",
    "        self.t2 = time()\n",
    "        \n",
    "        # avoid dividing by zero\n",
    "        sigma_2_local[sigma_2_local == 0] = 1e-20\n",
    "        sigma_2_global[sigma_2_global == 0] = 1e-20\n",
    "\n",
    "        # conjugate\n",
    "        # Equation (11), S3VR paper\n",
    "        y_bar_conjugate = (y_global/sigma_2_global + n*y_local/sigma_2_local) / (1/sigma_2_global + n/sigma_2_local)\n",
    "        sigma_2_conjugate = 1 / (1/sigma_2_global + n/sigma_2_local)\n",
    "        self.t3 = time()\n",
    "        \n",
    "        # generate\n",
    "        max_sigma_2, min_sigma_2 = sigma_2_conjugate.max(), sigma_2_conjugate.min()\n",
    "        # Equation (12), S3VR paper\n",
    "        pu = (sigma_2_conjugate - min_sigma_2) / (max_sigma_2 - min_sigma_2)\n",
    "        X_hat = np.vstack((self.labeled_X, self.unlabeled_X[(pu >= self.r).reshape(-1,)]))\n",
    "        y_hat = np.append(self.y.copy(), y_bar_conjugate[pu >= self.r])\n",
    "        self.t4 = time()\n",
    "\n",
    "        return X_hat, y_hat\n",
    "\n",
    "    def fit(self, labeled_X, y, unlabeled_X):\n",
    "        \"\"\"Train the S3VR model on the datasets\n",
    "\n",
    "        Args:\n",
    "            labeled_X (np.ndarray): the labeled X with shape (n_labeled, d)\n",
    "            y (np.ndarray): the labels with shape (n_labeled,) corresponding to the labeled X\n",
    "            unlabeled_X (np.ndarray): the unlabeled X with shape (n_unlabeled, d)\n",
    "        \"\"\"\n",
    "        self.labeled_X = labeled_X\n",
    "        self.y = y\n",
    "        self.unlabeled_X = unlabeled_X\n",
    "\n",
    "        X_hat, y_hat = self.data_generation()\n",
    "        self.svr = SVR()\n",
    "        self.svr.fit(X_hat, y_hat)\n",
    "        self.t5 = time()\n",
    "\n",
    "        print(f't1: {self.t1-self.t0}')\n",
    "        print(f't2: {self.t2-self.t1}')\n",
    "        print(f't2: {self.t3-self.t2}')\n",
    "        print(f't2: {self.t4-self.t3}')\n",
    "        print(f't2: {self.t5-self.t4}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict on X using the trained S3VR model\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): the datasets to be predicted with shape (n_X, d)\n",
    "\n",
    "        Raises:\n",
    "            ValueError: the svr is not trained\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: the predictions of the dataset X with shape (n_X,)\n",
    "        \"\"\"\n",
    "        if not self.svr:\n",
    "            raise ValueError(\"No SVR is fitted.\")\n",
    "\n",
    "        return self.svr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3vr = S3VR(5, 10, 0.5, 10)\n",
    "s3vr.fit(labeled_X, y[:, 0], unlabeled_X)\n",
    "preds = s3vr.predict(labeled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3vr = S3VR(5, 10, 0.5, 10)\n",
    "s3vr.fit(labeled_X, y[:, 0], unlabeled_X)\n",
    "preds = s3vr.predict(labeled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_X = np.load('labeled_data.npy')\n",
    "unlabeled_X = np.load('unlabeled_data.npy')\n",
    "y = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "distance.cdist(unlabeled_X, labeled_X, 'euclidean')\n",
    "time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "for i in range(10):\n",
    "    euclidean_distances(unlabeled_X, labeled_X)\n",
    "time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_X = labeled_X.astype(np.float64)\n",
    "unlabeled_X = unlabeled_X.astype(np.float64)\n",
    "y = y.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "for i in range(10):\n",
    "    euclidean_distances(unlabeled_X, labeled_X)\n",
    "time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: 9.118608713150024\n",
      "t2: 2.3686609268188477\n",
      "t2: 0.0009975433349609375\n",
      "t2: 0.0029926300048828125\n",
      "t2: 2.6758415699005127\n"
     ]
    }
   ],
   "source": [
    "s3vr = S3VR(5, 10, 0.5, 10)\n",
    "s3vr.fit(labeled_X, y[:, 0], unlabeled_X)\n",
    "preds = s3vr.predict(labeled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: 9.108633518218994\n",
      "t2: 2.3606841564178467\n",
      "t2: 0.0\n",
      "t2: 0.0019953250885009766\n",
      "t2: 2.8723158836364746\n"
     ]
    }
   ],
   "source": [
    "s3vr = S3VR(5, 10, 0.5, 10)\n",
    "s3vr.fit(labeled_X, y[:, 0], unlabeled_X)\n",
    "preds = s3vr.predict(labeled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a304760048decebaa3de9d5d5e7ae0455d0e991d0ed55e3d38e6237363fea8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
